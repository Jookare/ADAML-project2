{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>meantemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>meanpressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>114</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2017-02-26 12:00:00</td>\n",
       "      <td>21.713079</td>\n",
       "      <td>56.258362</td>\n",
       "      <td>8.143924</td>\n",
       "      <td>1004.035090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>1.387500</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2017-01-29 06:00:00</td>\n",
       "      <td>16.437198</td>\n",
       "      <td>39.625000</td>\n",
       "      <td>5.563542</td>\n",
       "      <td>1007.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2017-02-26 12:00:00</td>\n",
       "      <td>19.875000</td>\n",
       "      <td>57.750000</td>\n",
       "      <td>8.069444</td>\n",
       "      <td>1012.739316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2017-03-26 18:00:00</td>\n",
       "      <td>27.705357</td>\n",
       "      <td>71.902778</td>\n",
       "      <td>10.068750</td>\n",
       "      <td>1016.739583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2017-04-24 00:00:00</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>95.833333</td>\n",
       "      <td>19.314286</td>\n",
       "      <td>1022.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.360072</td>\n",
       "      <td>19.068083</td>\n",
       "      <td>3.588049</td>\n",
       "      <td>89.474692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date    meantemp    humidity  wind_speed  meanpressure\n",
       "count                  114  114.000000  114.000000  114.000000    114.000000\n",
       "mean   2017-02-26 12:00:00   21.713079   56.258362    8.143924   1004.035090\n",
       "min    2017-01-01 00:00:00   11.000000   17.750000    1.387500     59.000000\n",
       "25%    2017-01-29 06:00:00   16.437198   39.625000    5.563542   1007.437500\n",
       "50%    2017-02-26 12:00:00   19.875000   57.750000    8.069444   1012.739316\n",
       "75%    2017-03-26 18:00:00   27.705357   71.902778   10.068750   1016.739583\n",
       "max    2017-04-24 00:00:00   34.500000   95.833333   19.314286   1022.809524\n",
       "std                    NaN    6.360072   19.068083    3.588049     89.474692"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils import pretreat_data\n",
    "import seaborn as sns\n",
    "\n",
    "from utils import rolling_train_valid_split\n",
    "from dataset import TimeSeriesDataset\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "# use importlib magic so that if changes is made in the models, no need to restart the jupyter notebook\n",
    "from importlib import reload\n",
    "import models\n",
    "import trainer\n",
    "import transformer_model\n",
    "reload(models)\n",
    "reload(trainer)\n",
    "reload(transformer_model)\n",
    "\n",
    "from trainer import train, validate, test\n",
    "from transformer_model import TransformerForecaster, DecoderForecaster\n",
    "from models import RNN_model, LSTM_model\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "colors = sns.color_palette(\"colorblind6\")\n",
    "\n",
    "# Path to the data\n",
    "train_path = \"../data/ClimateTrain.csv\"\n",
    "test_path = \"../data/ClimateTest.csv\"\n",
    "\n",
    "# Read as pandas dataframe and transform dates to datetime\n",
    "train_df_raw = pd.read_csv(train_path)\n",
    "train_df_raw['date'] = pd.to_datetime(train_df_raw['date'])\n",
    "\n",
    "test_df_raw = pd.read_csv(test_path)\n",
    "test_df_raw['date'] = pd.to_datetime(test_df_raw['date'])\n",
    "\n",
    "# Plot description\n",
    "train_df_raw.describe()\n",
    "test_df_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretreat the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-treating data...\n",
      "{'meantemp': {'mean': 25.495520655761762, 'std': 7.348102725432476}, 'humidity': {'mean': 60.749546508715525, 'std': 16.79073354358986}, 'wind_speed': {'mean': 6.634903591220332, 'std': 4.24227584263327}, 'meanpressure': {'mean': 1008.2364359217448, 'std': 7.4472597886225085}}\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df, norm_stats = pretreat_data(train_df_raw, test_df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(gt, pred):\n",
    "    return np.sqrt(((pred - gt)**2).mean())\n",
    "\n",
    "def SMAPE(gt, pred):\n",
    "    return ( (np.abs(pred - gt)) / ((np.abs(gt) + np.abs(pred))/2) ).mean()\n",
    "\n",
    "def form_testdata(window_size, horizon):\n",
    "    # Add The required windows size to the test df so that we can start predicting from the beginning\n",
    "    test_horizon = horizon\n",
    "    test_start_date = test_df[\"date\"].loc[0]\n",
    "    test_window_date = test_start_date - pd.Timedelta(days=window_size+test_horizon)\n",
    "    filtered_train_df = train_df[(train_df['date'] > test_window_date) & (train_df['date'] < test_start_date)]\n",
    "    test_df_altered = pd.concat([filtered_train_df, test_df], ignore_index=True)\n",
    "    return test_df_altered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 RNN and LSTM models\n",
    "\n",
    "(Transformer at section 1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated configurations for ablation:\n",
      "{'window_size': 5, 'hidden_size': 128, 'embed_dim': 128, 'n_layers': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "{'window_size': 10, 'hidden_size': 128, 'embed_dim': 128, 'n_layers': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'n_layers': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "{'window_size': 30, 'hidden_size': 128, 'embed_dim': 128, 'n_layers': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "{'window_size': 180, 'hidden_size': 128, 'embed_dim': 128, 'n_layers': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# RNN & LSTM\n",
    "hyperparameter_space = {\n",
    "    \"window_size\": [5, 10, 20, 30, 180],\n",
    "    \"hidden_size\": [8, 32, 64, 128, 256],\n",
    "    \"embed_dim\": [8, 32, 64, 128, 256],\n",
    "    \"n_layers\": [1, 2, 4, 8],\n",
    "    \"dropout_p\": [0.2, 0.4, 0.6, 0.8],\n",
    "    \"date_as_var\": [True, False]\n",
    "}\n",
    "\n",
    "# Set a baseline configuration\n",
    "baseline = {\n",
    "    \"window_size\": 20,\n",
    "    \"hidden_size\": 128,\n",
    "    \"embed_dim\": 128,\n",
    "    \"n_layers\": 2,\n",
    "    \"dropout_p\": 0.2,\n",
    "    \"output_size\": 1,\n",
    "    \"date_as_var\": True\n",
    "}\n",
    "\n",
    "# Generate all combinations of hyperparameters\n",
    "configs = list(product(\n",
    "    hyperparameter_space['window_size'],\n",
    "    hyperparameter_space['hidden_size'],\n",
    "    hyperparameter_space['embed_dim'],\n",
    "    hyperparameter_space['n_layers'],\n",
    "    hyperparameter_space['dropout_p'],\n",
    "    hyperparameter_space['date_as_var'],\n",
    "))\n",
    "\n",
    "# Generate configurations for ablation study\n",
    "ablation_configs = []\n",
    "\n",
    "for param, values in hyperparameter_space.items():\n",
    "    for value in values:\n",
    "        # Create a copy of the baseline and modify the current parameter\n",
    "        config = baseline.copy()\n",
    "        config[param] = value\n",
    "        ablation_configs.append(config)\n",
    "\n",
    "print(\"Generated configurations for ablation:\")\n",
    "for config in ablation_configs[:5]:\n",
    "    print(config)\n",
    "\n",
    "# Define model\n",
    "model_type = \"LSTM\"\n",
    "\n",
    "# Set Horizon\n",
    "horizon = 1\n",
    "batch_size = 128\n",
    "n_epochs = 100\n",
    "lr = 0.0001\n",
    "\n",
    "# Configure logging\n",
    "os.makedirs(\"./logs\", exist_ok=True)\n",
    "logging.basicConfig(\n",
    "    filename=f\"./logs/training_{model_type}.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'window_size': 5, 'hidden_size': 128, 'embed_dim': 128, 'n_layers': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 13.77\n",
      "SMAPE: 0.228\n",
      "{'window_size': 10, 'hidden_size': 128, 'embed_dim': 128, 'n_layers': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 12.06\n",
      "SMAPE: 0.201\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'n_layers': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 12.16\n",
      "SMAPE: 0.203\n",
      "{'window_size': 30, 'hidden_size': 128, 'embed_dim': 128, 'n_layers': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 12.48\n",
      "SMAPE: 0.208\n",
      "{'window_size': 180, 'hidden_size': 128, 'embed_dim': 128, 'n_layers': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 20.00\n",
      "SMAPE: 0.306\n",
      "{'window_size': 20, 'hidden_size': 8, 'embed_dim': 128, 'n_layers': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 65\u001b[0m\n\u001b[0;32m     63\u001b[0m avg_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m---> 65\u001b[0m     avg_train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m     loss_history[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(avg_train_loss)\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m valid_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Joona\\Documents\\GitHub\\ADAML-project2\\Train\\trainer.py:17\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, criterion, optimizer, device, model_type)\u001b[0m\n\u001b[0;32m     13\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRNN\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Initialize the hidden state\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     prev_state \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Pass the input through the model\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     outputs, _ \u001b[38;5;241m=\u001b[39m model(inputs, prev_state)\n",
      "File \u001b[1;32mc:\\Users\\Joona\\Documents\\GitHub\\ADAML-project2\\Train\\models.py:82\u001b[0m, in \u001b[0;36mLSTM_model.init_state\u001b[1;34m(self, batch_size, device)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_size, device):\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# return tuple\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m     h0 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     83\u001b[0m     c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers, batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (h0,c0)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for idx, config in enumerate(ablation_configs):\n",
    "    torch.manual_seed(42)\n",
    "    print(config)\n",
    "    window_size = config[\"window_size\"]\n",
    "    hidden_size = config[\"hidden_size\"]\n",
    "    embed_dim = config[\"embed_dim\"]\n",
    "    n_layers = config[\"n_layers\"]\n",
    "    dropout_p = config[\"dropout_p\"] \n",
    "    output_size = config[\"output_size\"]\n",
    "    date_as_var = config[\"date_as_var\"]\n",
    "    \n",
    "    # Log the start of the experiment with hyperparameter details\n",
    "    logging.info(\n",
    "        f\"Starting Experiment {idx + 1}/{len(ablation_configs)}\\n\"\n",
    "        f\"Hyperparameters:\\n\"\n",
    "        f\"  window_size={window_size}, hidden_size={hidden_size}, embed_dim={embed_dim},\"\n",
    "        f\"  n_layers={n_layers}, dropout_p={dropout_p}, output_size={output_size},\"\n",
    "        f\"  date_as_var={date_as_var}\"\n",
    "    )\n",
    "\n",
    "    if date_as_var:\n",
    "        input_size = 6\n",
    "    else:\n",
    "        input_size = 4\n",
    "\n",
    "    match model_type:\n",
    "        case \"RNN\":\n",
    "            model = RNN_model(hidden_size=hidden_size, embed_dim = embed_dim, n_layers=n_layers, input_size=input_size, out_features=output_size, dropout_p=dropout_p)\n",
    "        case \"LSTM\":\n",
    "            model = LSTM_model(hidden_size=hidden_size, embed_dim = embed_dim, n_layers=n_layers, input_size=input_size, out_features=output_size, dropout_p=dropout_p)\n",
    "        case \"Transformer\":\n",
    "            model = model = TransformerForecaster(hidden_size=hidden_size, embed_dim = embed_dim, \n",
    "                                encoder_heads=4, encoder_depth=4,\n",
    "                                decoder_heads=4, decoder_depth=4, \n",
    "                                input_size=input_size, out_features=output_size, dropout_p=dropout_p)\n",
    "        case \"Decoder\":\n",
    "            model = DecoderForecaster(hidden_size=hidden_size, embed_dim = embed_dim, \n",
    "                            decoder_heads=2, decoder_depth=1, \n",
    "                            input_size=input_size, out_features=output_size, dropout_p=dropout_p)\n",
    "        case _:\n",
    "                \"Something's wrong with the model_type\"\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr, weight_decay=0.03)\n",
    "\n",
    "        # Generate rolling train-validation splits\n",
    "    loss_history = {0: {\"train\": [], \"valid\": []}, \n",
    "                    1: {\"train\": [], \"valid\": []}, \n",
    "                    2: {\"train\": [], \"valid\": []},\n",
    "                    3: {\"train\": []}}\n",
    "    for i, (train_data, valid_data) in enumerate(rolling_train_valid_split(train_df, months=6, window_size=window_size, horizon=horizon)):\n",
    "        # print(\"Training fold \", i)\n",
    "        train_dataset = TimeSeriesDataset(df=train_data, window_size=window_size, horizon=horizon, date_as_var=date_as_var)\n",
    "        if valid_data is not None:\n",
    "            valid_dataset = TimeSeriesDataset(df=valid_data, window_size=window_size, horizon=horizon, date_as_var=date_as_var)\n",
    "        \n",
    "        # Initialize the dataloaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "\n",
    "        avg_val_loss = 0\n",
    "        for epoch in range(n_epochs):\n",
    "            avg_train_loss = train(model, train_loader, criterion, optimizer, device, model_type)\n",
    "            \n",
    "            loss_history[i][\"train\"].append(avg_train_loss)\n",
    "            \n",
    "            if valid_data is not None:\n",
    "                avg_val_loss = validate(model, valid_loader, criterion, device, model_type)\n",
    "                loss_history[i][\"valid\"].append(avg_val_loss)\n",
    "            # print(f\"Epoch {epoch+1}/{n_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "    # Create the test dataset\n",
    "    test_df_altered = form_testdata(window_size, horizon)\n",
    "    test_dataset = TimeSeriesDataset(df=test_df_altered, window_size=window_size, horizon=horizon, date_as_var=date_as_var)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Test the model\n",
    "    gt, pred = test(model, test_dataset, device, model_type)\n",
    "\n",
    "    gt = gt*norm_stats[\"humidity\"][\"std\"] + norm_stats[\"humidity\"][\"mean\"]\n",
    "    pred = pred*norm_stats[\"humidity\"][\"std\"] + norm_stats[\"humidity\"][\"mean\"]\n",
    "\n",
    "    mean_rmse = RMSE(gt, pred)\n",
    "    mean_smape = SMAPE(gt, pred)\n",
    "    logging.info(f\"RMSE, SMAPE: {mean_rmse:.2f} & {mean_smape:.3f}\")\n",
    "    \n",
    "    print(f\"RMSE: {mean_rmse:.2f}\")\n",
    "    print(f\"SMAPE: {mean_smape:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Transformer models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated configurations for ablation:\n",
      "{'window_size': 5, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "{'window_size': 10, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "{'window_size': 30, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "{'window_size': 20, 'hidden_size': 8, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# RNN & LSTM\n",
    "hyperparameter_space = {\n",
    "    \"window_size\": [5, 10, 20, 30],\n",
    "    \"hidden_size\": [8, 32, 64, 128, 256],\n",
    "    \"embed_dim\":   [8, 32, 64, 128, 256],\n",
    "    \"encoder_heads\": [1, 2, 4, 8],\n",
    "    \"encoder_depth\": [1, 2, 4, 8],\n",
    "    \"decoder_heads\": [1, 2, 4, 8],\n",
    "    \"decoder_depth\": [1, 2, 4, 8],\n",
    "    \"dropout_p\": [0.2, 0.4, 0.6, 0.8],\n",
    "    \"date_as_var\": [True, False]\n",
    "}\n",
    "\n",
    "# Set a baseline configuration\n",
    "baseline = {\n",
    "    \"window_size\": 20,\n",
    "    \"hidden_size\": 128,\n",
    "    \"embed_dim\": 128,\n",
    "    \"encoder_heads\": 4,\n",
    "    \"encoder_depth\": 2,\n",
    "    \"decoder_heads\": 4,\n",
    "    \"decoder_depth\": 2,\n",
    "    \"dropout_p\": 0.2,\n",
    "    \"output_size\": 1,\n",
    "    \"date_as_var\": True\n",
    "}\n",
    "\n",
    "# Generate all combinations of hyperparameters\n",
    "configs = list(product(\n",
    "    hyperparameter_space['window_size'],\n",
    "    hyperparameter_space['hidden_size'],\n",
    "    hyperparameter_space['embed_dim'],\n",
    "    hyperparameter_space['encoder_heads'],\n",
    "    hyperparameter_space['encoder_depth'],\n",
    "    hyperparameter_space['decoder_heads'],\n",
    "    hyperparameter_space['decoder_depth'],\n",
    "    hyperparameter_space['dropout_p'],\n",
    "    hyperparameter_space['date_as_var'],\n",
    "))\n",
    "\n",
    "# Generate configurations for ablation study\n",
    "ablation_configs = []\n",
    "\n",
    "for param, values in hyperparameter_space.items():\n",
    "    for value in values:\n",
    "        # Create a copy of the baseline and modify the current parameter\n",
    "        config = baseline.copy()\n",
    "        config[param] = value\n",
    "        ablation_configs.append(config)\n",
    "\n",
    "print(\"Generated configurations for ablation:\")\n",
    "for config in ablation_configs[:5]:\n",
    "    print(config)\n",
    "\n",
    "# Define model\n",
    "model_type = \"Decoder\"\n",
    "\n",
    "# Set Horizon\n",
    "horizon = 1\n",
    "batch_size = 128\n",
    "n_epochs = 100\n",
    "lr = 0.0001\n",
    "\n",
    "# Configure logging\n",
    "os.makedirs(\"./logs\", exist_ok=True)\n",
    "logging.basicConfig(\n",
    "    filename=f\"./logs/training_{model_type}.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'window_size': 5, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 7.29\n",
      "SMAPE: 0.119\n",
      "{'window_size': 10, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 7.24\n",
      "SMAPE: 0.120\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 7.04\n",
      "SMAPE: 0.114\n",
      "{'window_size': 30, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 7.07\n",
      "SMAPE: 0.113\n",
      "{'window_size': 20, 'hidden_size': 8, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 6.93\n",
      "SMAPE: 0.111\n",
      "{'window_size': 20, 'hidden_size': 32, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 6.89\n",
      "SMAPE: 0.108\n",
      "{'window_size': 20, 'hidden_size': 64, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 7.03\n",
      "SMAPE: 0.111\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 7.04\n",
      "SMAPE: 0.114\n",
      "{'window_size': 20, 'hidden_size': 256, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 7.09\n",
      "SMAPE: 0.112\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 8, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 11.20\n",
      "SMAPE: 0.184\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 32, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 7.71\n",
      "SMAPE: 0.119\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 64, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 6.79\n",
      "SMAPE: 0.108\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 7.04\n",
      "SMAPE: 0.114\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 256, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 6.96\n",
      "SMAPE: 0.112\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 1, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 7.04\n",
      "SMAPE: 0.114\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 2, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 7.04\n",
      "SMAPE: 0.114\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 7.04\n",
      "SMAPE: 0.114\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 8, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 7.04\n",
      "SMAPE: 0.114\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 1, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 7.04\n",
      "SMAPE: 0.114\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 7.04\n",
      "SMAPE: 0.114\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 4, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 7.04\n",
      "SMAPE: 0.114\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 8, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 7.04\n",
      "SMAPE: 0.114\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 1, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 6.97\n",
      "SMAPE: 0.112\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 2, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 6.89\n",
      "SMAPE: 0.110\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 7.04\n",
      "SMAPE: 0.114\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 8, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 6.98\n",
      "SMAPE: 0.113\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 1, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 6.97\n",
      "SMAPE: 0.111\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 7.04\n",
      "SMAPE: 0.114\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 4, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 7.02\n",
      "SMAPE: 0.110\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 8, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 7.03\n",
      "SMAPE: 0.113\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 7.04\n",
      "SMAPE: 0.114\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.4, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 7.43\n",
      "SMAPE: 0.123\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.6, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 8.24\n",
      "SMAPE: 0.140\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.8, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 8.47\n",
      "SMAPE: 0.125\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': True}\n",
      "RMSE: 7.04\n",
      "SMAPE: 0.114\n",
      "{'window_size': 20, 'hidden_size': 128, 'embed_dim': 128, 'encoder_heads': 4, 'encoder_depth': 2, 'decoder_heads': 4, 'decoder_depth': 2, 'dropout_p': 0.2, 'output_size': 1, 'date_as_var': False}\n",
      "RMSE: 7.01\n",
      "SMAPE: 0.111\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idx, config in enumerate(ablation_configs):\n",
    "    torch.manual_seed(42)\n",
    "    print(config)\n",
    "    window_size = config[\"window_size\"]\n",
    "    hidden_size = config[\"hidden_size\"]\n",
    "    embed_dim = config[\"embed_dim\"]\n",
    "    encoder_heads = config[\"encoder_heads\"]\n",
    "    encoder_depth = config[\"encoder_depth\"]\n",
    "    decoder_heads = config[\"decoder_heads\"]\n",
    "    decoder_depth = config[\"decoder_depth\"]\n",
    "    dropout_p = config[\"dropout_p\"] \n",
    "    output_size = config[\"output_size\"]\n",
    "    date_as_var = config[\"date_as_var\"]\n",
    "    \n",
    "    # Log the start of the experiment with hyperparameter details\n",
    "    logging.info(\n",
    "        f\"Starting Experiment {idx + 1}/{len(ablation_configs)}\\n\"\n",
    "        f\"Hyperparameters:\\n\"\n",
    "        f\"  window_size={window_size}, hidden_size={hidden_size}, embed_dim={embed_dim},\"\n",
    "        f\"  encoder_heads={encoder_heads}, encoder_depth={encoder_depth}, \"\n",
    "        f\"  decoder_heads={decoder_heads}, decoder_depth={decoder_depth}, \"\n",
    "        f\"  dropout_p={dropout_p}, output_size={output_size},\"\n",
    "        f\"  date_as_var={date_as_var}\"\n",
    "    )\n",
    "\n",
    "    if date_as_var:\n",
    "        input_size = 6\n",
    "    else:\n",
    "        input_size = 4\n",
    "\n",
    "    match model_type:\n",
    "        case \"RNN\":\n",
    "            model = RNN_model(hidden_size=hidden_size, embed_dim = embed_dim, n_layers=n_layers, input_size=input_size, out_features=output_size, dropout_p=dropout_p)\n",
    "        case \"LSTM\":\n",
    "            model = LSTM_model(hidden_size=hidden_size, embed_dim = embed_dim, n_layers=n_layers, input_size=input_size, out_features=output_size, dropout_p=dropout_p)\n",
    "        case \"Transformer\":\n",
    "            model = model = TransformerForecaster(hidden_size=hidden_size, embed_dim = embed_dim, \n",
    "                                encoder_heads=encoder_heads, encoder_depth=encoder_depth,\n",
    "                                decoder_heads=decoder_heads, decoder_depth=decoder_depth, \n",
    "                                input_size=input_size, out_features=output_size, dropout_p=dropout_p)\n",
    "        case \"Decoder\":\n",
    "            model = DecoderForecaster(hidden_size=hidden_size, embed_dim = embed_dim, \n",
    "                            decoder_heads=decoder_heads, decoder_depth=decoder_depth, \n",
    "                            input_size=input_size, out_features=output_size, dropout_p=dropout_p)\n",
    "        case _:\n",
    "                \"Something's wrong with the model_type\"\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr, weight_decay=0.03)\n",
    "\n",
    "        # Generate rolling train-validation splits\n",
    "    loss_history = {0: {\"train\": [], \"valid\": []}, \n",
    "                    1: {\"train\": [], \"valid\": []}, \n",
    "                    2: {\"train\": [], \"valid\": []},\n",
    "                    3: {\"train\": []}}\n",
    "    for i, (train_data, valid_data) in enumerate(rolling_train_valid_split(train_df, months=6, window_size=window_size, horizon=horizon)):\n",
    "        # print(\"Training fold \", i)\n",
    "        train_dataset = TimeSeriesDataset(df=train_data, window_size=window_size, horizon=horizon, date_as_var=date_as_var)\n",
    "        if valid_data is not None:\n",
    "            valid_dataset = TimeSeriesDataset(df=valid_data, window_size=window_size, horizon=horizon, date_as_var=date_as_var)\n",
    "        \n",
    "        # Initialize the dataloaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "\n",
    "        avg_val_loss = 0\n",
    "        for epoch in range(n_epochs):\n",
    "            avg_train_loss = train(model, train_loader, criterion, optimizer, device, model_type)\n",
    "            \n",
    "            loss_history[i][\"train\"].append(avg_train_loss)\n",
    "            \n",
    "            if valid_data is not None:\n",
    "                avg_val_loss = validate(model, valid_loader, criterion, device, model_type)\n",
    "                loss_history[i][\"valid\"].append(avg_val_loss)\n",
    "            # print(f\"Epoch {epoch+1}/{n_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "    # Create the test dataset\n",
    "    test_df_altered = form_testdata(window_size, horizon)\n",
    "    test_dataset = TimeSeriesDataset(df=test_df_altered, window_size=window_size, horizon=horizon, date_as_var=date_as_var)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Test the model\n",
    "    gt, pred = test(model, test_dataset, device, model_type)\n",
    "\n",
    "    gt = gt*norm_stats[\"humidity\"][\"std\"] + norm_stats[\"humidity\"][\"mean\"]\n",
    "    pred = pred*norm_stats[\"humidity\"][\"std\"] + norm_stats[\"humidity\"][\"mean\"]\n",
    "\n",
    "    mean_rmse = RMSE(gt, pred)\n",
    "    mean_smape = SMAPE(gt, pred)\n",
    "    logging.info(f\"RMSE, SMAPE: {mean_rmse:.2f} & {mean_smape:.3f}\")\n",
    "    \n",
    "    print(f\"RMSE: {mean_rmse:.2f}\")\n",
    "    print(f\"SMAPE: {mean_smape:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
